---
confluent_services:
  - kafka
  - kafka-rest
  - zookeeper

kafka_ip: "{{ ansible_all_ipv4_addresses | first }}"
kafka_plaintext_port: 9092
kafka_security_port: 9093
kafka_group: >-
  {%- if groups['kafka'] is defined -%}
  {{ groups['kafka'] }}
  {%- else -%}
  {{ ansible_play_hosts }}
  {%- endif -%}

kafka_system_users:
  enabled: yes
  group: wheel
  permissions:
    directory_mode: "0750"
    file_mode: "0640"
  include_to_sudoers: yes

dst_path: "/opt"
local_path: "/tmp"
confluent_version: "5.4.0"
scala_version: "2.12"
confluent_distribution: "confluent-community"
confluent_base: http://packages.confluent.io/archive
confluent_package_file: >-
  {{ confluent_version[:3] }}/{{ confluent_distribution }}
  -{{ confluent_version }}-{{ scala_version }}.tar.gz
confluent_url: "{{ confluent_base }}/{{ confluent_package_file | replace(' ', '') }}"

log_basepath: "/var/log"
data_basepath: "/var/data"
initscripts_path: "/usr/sbin"
conf_dest: "/etc/config"

# Oracle Java necessary vars. IF you are using ansiblebit.oracle-java
oracle_java_set_as_default: yes
oracle_java_version: 8

## Kafka Vars
reserved_broker_max: 10000
delete_topic_enable: "true"
num_network_threads: 3
num_io_threads: 8

socket_send_buffer_bytes: 102400
socket_receive_buffer_bytes: 102400
socket_request_max_bytes: 104857600

log_dir: "{{ log_basepath }}/kafka"
num_partitions: 1
num_recovery_threads_per_data_dir: 1
log_flush_interval_messages: 10000
log_flush_interval_ms: 1000
log_retention_hours: 6
log_retention_bytes: 1073741824
log_segment_bytes: 1073741824
log_retention_check_interval_ms: 300000
ion_timeout_ms: 6000

confluent_support_metrics_enable: yes
confluent_support_customer_id: "anonymous"
auto_create_topics: no
default_replication_factor: 1
offsets_replication_factor: "{{ [ kafka_group | length, 3 ] | min }}"
min_insync_replicas: 1

ssl:
  path: /var/private/ssl

local:
  files: ../files

## Kafka SSL Vars
kafka_security:
  server:
    keystore: "kafka.server.keystore.jks"
    truststore: "kafka.server.truststore.jks"
  client:
    truststore: "kafka.client.truststore.jks"

## Schema Registry Vars
listeners_schema: "http://0.0.0.0:8081"
kafkastore_topic: "schema-registry"
schema_registry_debug: "false"

## Zookeeper Vars
zookeeper_group: "{{ groups['zookeeper'] | default(ansible_play_hosts) }}"
zookeepers: >
  "{% for server in zookeeper_group -%}
  {{ hostvars.get(server).ansible_all_ipv4_addresses | first }}:{{ zookeeper_port }}
  {% endfor %}"
zookeeper_port: 2181
zookeeper_connect: "{{ zookeepers.split() | join(',') }}"
zookeeper_data_dir: "{{ data_basepath }}/zookeeper"
zookeeper_log_dir: "{{ data_basepath }}/logs/zookeeper"
zookeeper_max_cnxns: 0
zookeeper_init_limit: 5
zookeeper_sync_limit: 3
zookeeper_connection_timeout: 6000

## Services
kafka_services:
  kafka:
    file_name: "kafka"
    user: "kafka"
    daemon_start: "{{ dst_path }}/confluent-{{ confluent_version }}/bin/kafka-server-start"
    daemon_stop: "{{ dst_path }}/confluent-{{ confluent_version }}/bin/kafka-server-stop"
    daemon_status: "ps ax | grep -i 'Kafka.properties' | grep java > /dev/null"
    daemon_opts: "{% if ansible_service_mgr == 'upstart' %}-daemon {% endif %}{{ conf_dest }}/kafka.properties"
    state: "started"
    enabled: yes

  kafka-rest:
    file_name: "kafka-rest"
    user: "kafka"
    daemon_start: "{{ dst_path }}/confluent-{{ confluent_version }}/bin/kafka-rest-start"
    daemon_stop: "{{ dst_path }}/confluent-{{ confluent_version }}/bin/kafka-rest-stop"
    daemon_status: "ps ax | grep -i 'kafka-rest' | grep java > /dev/null"
    daemon_opts: " -daemon"
    state: "started"
    enabled: yes

zookeeper_services:
  zookeeper:
    file_name: "zookeeper"
    user: "zookeeper"
    daemon_start: "{{ dst_path }}/confluent-{{ confluent_version }}/bin/zookeeper-server-start"
    daemon_stop: "{{ dst_path }}/confluent-{{ confluent_version }}/bin/zookeeper-server-stop"
    daemon_status: "ps ax | grep -i 'zookeeper.properties' | grep java > /dev/null"
    daemon_opts: >-
      {% if ansible_service_mgr in [ 'upstart', 'sysvinit' ] -%}
      -daemon
      {%- endif -%}
      {{ conf_dest }}/zookeeper.properties
    state: "started"
    enabled: yes
# default_kafka_topics:
## Create a test topic with retention.ms set
#  - name: test_topic
#    state: present # optional defaults to true
#    config:
#       - item: retention.ms
#         value: 3600000
## Create a 2nd test topic with defaults
#  - name: test_topic_2
## Create a 3rd test topic with compression.type and file.delete.delay.ms set
#  - name: test_topic_3
#    partitions: 24
#    replication_factor: 2
#    config:
#       - item: compression.type
#         value: zip
#       - item: file.delete.delay.ms
#         value: 30000
## Ensure our topic does no longer exist if it is in the topic list
#  - name: unused_topic
#    state: absent

#Log4J Vars
log4j_logDir: "{{ dst_path }}/confluent-{{ confluent_version }}/logs"

log4j_rootLogger: "INFO, stdout, kafkaAppender"

log4j_stdout_class: "org.apache.log4j.ConsoleAppender"

log4j_kafkaAppender_class: "org.apache.log4j.RollingFileAppender"
log4j_kafkaAppender_file: "{{ log4j_logDir }}/server.log"
log4j_kafkaAppender_maxFileSize: "10MB"
log4j_kafkaAppender_maxBackupIndex: "100"

log4j_stateChangeAppender_class: "org.apache.log4j.RollingFileAppender"
log4j_stateChangeAppender_file: "{{ log4j_logDir }}/state-change.log"
log4j_stateChangeAppender_maxFileSize: "10MB"
log4j_stateChangeAppender_maxBackupIndex: "100"

log4j_requestAppender_class: "org.apache.log4j.RollingFileAppender"
log4j_requestAppender_file: "{{ log4j_logDir }}/kafka-request.log"
log4j_requestAppender_maxFileSize: "10MB"
log4j_requestAppender_maxBackupIndex: "100"

log4j_cleanerAppender_class: "org.apache.log4j.RollingFileAppender"
log4j_cleanerAppender_file: "{{ log4j_logDir }}/log-cleaner.log"
log4j_cleanerAppender_maxFileSize: "10MB"
log4j_cleanerAppender_maxBackupIndex: "100"

log4j_controllerAppender_class: "org.apache.log4j.RollingFileAppender"
log4j_controllerAppender_file: "{{ log4j_logDir }}/controller.log"
log4j_controllerAppender_maxFileSize: "10MB"
log4j_controllerAppender_maxBackupIndex: "100"

log4j_authorizerAppender_class: "org.apache.log4j.RollingFileAppender"
log4j_authorizerAppender_file: "{{ log4j_logDir }}/kafka-authorizer.log"
log4j_authorizerAppender_maxFileSize: "10MB"
log4j_authorizerAppender_maxBackupIndex: "100"

log4j_logger_zookeeper: "INFO"
log4j_logger_kafka_serverLog: "INFO"
log4j_logger_kafka_stdout: "INFO"

log4j_logger_kafka_requestLogger: "WARN, requestAppender"
log4j_additivity_kafka_requestLogger: "false"

log4j_logger_kafka_networkRequestChannel: "WARN, requestAppender"
log4j_additivity_kafka_networkRequestChannel: "false"

log4j_logger_kafka_controller: "TRACE, controllerAppender"
log4j_additivity_kafka_controller: "false"

log4j_logger_kafka_logCleaner: "INFO, cleanerAppender"
log4j_additivity_kafka_logCleaner: "false"

log4j_logger_kafka_stateChangeLogger: "TRACE, stateChangeAppender"
log4j_additivity_kafka_stateChangeLogger: "false"

log4j_logger_kafka_authorizerLogger: "INFO, authorizerAppender"
log4j_additivity_kafka_authorizerLogger: "false"
